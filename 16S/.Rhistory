estimated_power <- (num_null_rejects / 1000)
samplesize_effectsize_estimatedpower <- rbind(samplesize_effectsize_estimatedpower,
c(num_flips, coin_bias, estimated_power))
}
}
# estimated the estimated power and effect size
samplesize_effectsize_estimatedpower <- tibble("sample_size" = sprintf("%03d", samplesize_effectsize_estimatedpower[,1]),
"effect_size" = samplesize_effectsize_estimatedpower[,2],
"estimated_power" = samplesize_effectsize_estimatedpower[,3])
# Plotting power curves
samplesize_effectsize_estimatedpower %>%
ggplot(aes(x = effect_size,
y = estimated_power,
color = sample_size,
shape = sample_size)) +
scale_color_brewer(palette = "Dark2") +
geom_point() +
geom_line() +
theme_bw()
fair_num_heads
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
sd <- 10
effec.size <- -1.3
# effec.size=mean.diff/sd
mean.diff <- effec.size * sd
mean.diff
rnorm(1000)
data=rnorm(1000)
data
data=rnorm(1000, mean = -13, sd=10)
data
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
alpha <- 12 #the value of y that you get when x =0
sd <- 10
beta <- -1.3
# effec.size=mean.diff/sd
mean.diff <- effec.size * sd
sigma <- 10
y <- rnorm(1000, mean = -13, sd=10)
y
x <- rnorm(1000,20, 25)
x
x <- rnorm(1000,0, 25)
x
x <- 1:1000
x <- 1:1000
x
x <- rnorm(1000,100,10)
x
knitr::opts_chunk$set(echo = TRUE)
alpha <- 12
sigma <- 10
beta <- -1.3
# lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -13, sd=10)
x <- rnorm(1000,100,10)
# Estimating the mean of a normal
ln.L <- function(y,x,alpha,beta,sigma){
return(sum(
dnorm(y, mean=alpha + beta * x, sd=sigma, log=TRUE)
))
}
alpha <- 12
sigma <- 10
beta <- -1.3
lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -13, sd=10)
x <- rnorm(1000,100,10)
# Estimating the mean of a normal
ln.L <- function(y,x,alpha,beta,sigma){
return(sum(
dnorm(y, mean=alpha + beta * x, sd=sigma, log=TRUE)
))
}
ln.L(y,x,alpha,beta,sigma)
sum(dnorm(y, mean=alpha + beta * x, sd=sigma, log=TRUE)
)
lm <- lm(y ~ (beta*x + alpha, sigma)
data <- data.frame(x,y)
data
lm <- lm(y ~ (beta*x + alpha, sigma),data)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- rnorm(1000,100,10)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
alpha <- 12
sigma <- 10
beta <- -1.3
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(1000,100,10)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(1000,100,0)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(1000,100,10)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(1000,100,10)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(0,10,length.out=1000)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
# lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(1000, 100)
x
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
# lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- rnorm(1000, 100, 10)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
# lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- rnorm(1000, 10, 100)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
# lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(10,100, length.out = 1000)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
adonis(otu_dist~map$pod)
n1 <- 60  				# Number of females
n2 <- 40					# Number of males
mu1 <- 105					# Population mean of females
mu2 <- 77.5					# Population mean of males
sigma1 <- 3				# SD of females
sigma2 <- 2.5  # S
n <- n1+n2					# Total sample size
y1 <- rnorm(n1, mu1, sigma1)		# Data for females separately
y2 <- rnorm(n2, mu2, sigma2)		# Data for males separately
n <- n1+n2					# Total sample size
y1 <- rnorm(n1, mu1, sigma1)		# Data for females separately
y2 <- rnorm(n2, mu2, sigma2)		# Data for males separately
n
y1
y2
data2 <- data.frame(y=c(y1, y2), sex=c(rep("f",n1),rep("m",n2)))			# Aggregate both data sets
data2
boxplot(data2$y ~ data2$sex, col = "grey", xlab = "Sex", ylab = "Wingspan (cm)", las = 1)
#Simulate the data
n1 <- 60  				# Number of females
n2 <- 40					# Number of males
mu1 <- 105					# Population mean of females
mu2 <- 77.5					# Population mean of males
sigma <- 2.75				# Average population SD of both
n <- n1+n2					# Total sample size
y1 <- rnorm(n1, mu1, sigma)		# Data for females separately
y2 <- rnorm(n2, mu2, sigma)		# Data for males separately
data1 <- data.frame(y=c(y1, y2), sex=c(rep("f",n1),rep("m",n2)))			# Aggregate both data sets
boxplot(data1$y ~ data1$sex, col = "grey", xlab = "Sex", ylab = "Wingspan (cm)", las = 1)
n <- n1+n2  				# Total sample size
alpha <- mu1				# Mean for females serves as the intercept
beta <- mu2-mu1				# Beta is the difference male-female
E.y <- alpha + beta*x			# expectation
y.obs <- rnorm(n = n, mean = E.y, sd = sigma)	# Add random variation
x <- rep(c(0,1), c(n1, n2))		# Indicator for male
boxplot(y.obs ~ x, col = "grey", xlab = "Male", ylab = "Wingspan (cm)", las = 1)
fit1 <- lm(data1$y ~ data1$sex)  		# Analyze the data with an effects parameterization
fit2 <- lm(data1$y ~ data1$sex-1) 		# Analyze the data with a means parameterization
summary(fit1)
summary(fit2)
#Take a look at the design matrices for the two models (are they the same?):
model.matrix(fit1)
model.matrix(fit2)
#What is the interpretation of the coefficients?
fit1$coefficients
fit2$coefficients
#Is there a difference in wingspan between males and females?
#It's easiest to figure this out using fit1.  Why?
confint(fit1)
#But we can also tell with the means parameterization
confint(fit2)
#Pull out the residuals
residual = fit1$residuals
predicted= fit1$fitted.values
#Is there a pattern in the residuals?
plot(predicted, residual, main = "Residuals vs. predicted values",
las = 1, xlab = "Predicted values", ylab = "Residuals")
abline(h = 0)
#Another way to do this analysis is with the function t.test
t.test(data1$y ~ data1$sex, var.equal=TRUE)
#Simulate the data
n1 <- 60  				# Number of females
n2 <- 40					# Number of males
mu1 <- 105					# Population mean of females
mu2 <- 77.5					# Population mean of males
sigma1 <- 3				# SD of females
sigma2 <- 2.5  # SD of males
n <- n1+n2					# Total sample size
y1 <- rnorm(n1, mu1, sigma1)		# Data for females separately
y2 <- rnorm(n2, mu2, sigma2)		# Data for males separately
data2 <- data.frame(y=c(y1, y2), sex=c(rep("f",n1),rep("m",n2)))			# Aggregate both data sets
boxplot(data2$y ~ data2$sex, col = "grey", xlab = "Sex", ylab = "Wingspan (cm)", las = 1)
t.test(data2$y ~ data2$sex, var.equal=FALSE)
sample_names(phyloseq_map)
library(phyloseq)
sample_names(phyloseq_map)
# 1. BACTERIA COMPOSITION
# read bacterial taxonomy
tax_16S = read.csv("16S_TAX.csv", sep=',', header=T)
# Set the working directory
setwd('/Users/arifinabintarti/Documents/PAPER/PAPER_Bintarti_2019_Apple/')
wd <- print(getwd())
# 1. BACTERIA COMPOSITION
# read bacterial taxonomy
tax_16S = read.csv("16S_TAX.csv", sep=',', header=T)
tax_16S
rownames(tax_16S) <- rownames(otu)
# make phyloseq otu table and taxonomy
OTU = otu_table(otu, taxa_are_rows = TRUE)
TAX = tax_table(as.matrix(tax_16S))
# 1. BACTERIA COMPOSITION
# read bacterial taxonomy
tax_16S = read.csv("16S_TAX.csv", sep=',', header=T)
tax_16S
rownames(tax_16S) <- rownames(otu)
# read the bacterial OTU
otu <- read.table('OTU_rarefied_16S.txt', sep='\t', header=T, row.names = 1)
taxonomy <- otu[,'taxonomy']
taxonomy
# read the bacterial OTU
otu <- read.table('OTU_rarefied_16S.txt', sep='\t', header=T, row.names = 1)
taxonomy <- otu[,'taxonomy']
taxonomy
otu <- otu[,-46]
dim(otu) # there are 22,510 bacterial OTUs and 45 samples
rownames(tax_16S) <- rownames(otu)
# make phyloseq otu table and taxonomy
OTU = otu_table(otu, taxa_are_rows = TRUE)
TAX = tax_table(as.matrix(tax_16S))
# add map
# Read the metadata (map)
map <- read.table('clean_map_data.csv', sep=',', header=TRUE)
str(map) # We use number as the name of site and it is integer
map$Site <- as.factor(map$Site) # I want to change site as factor
colnames(map)[which(names(map) == "rootstock")] <- "Rootstock"
colnames(map)[which(names(map) == "cultivar")] <- "Scion"
map$Site<-as.factor(map$Site)
rownames(map) <- map$sample_code
head(map)
map$Site<-as.factor(map$Site)
rownames(map) <- map$sample_code
# make phyloseq map
phyloseq_map <- sample_data(map)
# make phyloseq object
PHYL_16S <- merge_phyloseq(OTU,TAX,phyloseq_map)
PHYL_16S
sample_names(phyloseq_map)
head(map)
colnames(map)
# add map
# Read the metadata (map)
map <- read.table('clean_map_data.csv', sep=',', header=TRUE)
str(map) # We use number as the name of site and it is integer
map$Site <- as.factor(map$Site) # I want to change site as factor
# add map
# Read the metadata (map)
map <- read.table('clean_map_data.csv', sep=',', header=TRUE)
str(map) # We use number as the name of site and it is integer
map$Site <- as.factor(map$Site) # I want to change site as factor
colnames(map)[which(names(map) == "rootstock")] <- "Rootstock"
colnames(map)[which(names(map) == "cultivar")] <- "Scion"
map$Site<-as.factor(map$Site)
head(map)
rownames(map) <- map$sample_code
head(map)
# SET THE WORKING DIRECTORY
rm(list=ls())
set.seed(3)
setwd('/Users/arifinabintarti/Documents/BioRxiv_Seed_Microbiome_2020/16S/')
wd <- print(getwd())
otu.rare.pat <- read.table('single_rare_filt.txt', sep='\t', header=T, row.names = 1)
colnames(otu.rare.pat)
taxonomy.rare.pat <- otu.rare.pat[,'taxonomy']
str(taxonomy.rare.pat)
#write.csv(taxonomy.rare.pat, file = "taxonomy.rare.pat.csv")
dim(otu.rare.pat)
otu.rare.pat <- otu.rare.pat[,-25]
dim(otu.rare.pat)
plant.data = read.csv("planthealthpat.csv", header=T)
map.pat <- plant.data
#checking the colsum and rowsum and produce rarefaction curve
sort(colSums(otu.rare.pat, na.rm = FALSE, dims = 1), decreasing = TRUE)
head(sort(rowSums(otu.rare.pat, na.rm = FALSE, dims = 1), decreasing = FALSE))
rarecurve(t(otu.rare.pat), step = 20, col = "blue", cex = 0.6) #produce the rarefaction curve
################################################################################################################
#calculate alpha diversity
otu.rare.pat <- as.data.frame(otu.rare.pat)
s <- specnumber(otu.rare.pat, MARGIN = 2) # richness
rich <- as.data.frame(s)
################################################################################################################
#calculate alpha diversity
otu.rare.pat <- as.data.frame(otu.rare.pat)
s <- specnumber(otu.rare.pat, MARGIN = 2) # richness
library(vegan)
library(plyr)
library(dplyr)
library(tidyverse)
library(tidyr)
library(cowplot)
library(ggplot2)
library(reshape)
library(ggpubr)
library(car)
library(agricolae)
library(multcompView)
library(grid)
library(gridExtra)
library(sjmisc)
library(sjPlot)
library(MASS)
library(FSA)
library(rcompanion)
library(onewaytests)
library(ggsignif)
library(PerformanceAnalytics)
library(gvlma)
library(userfriendlyscience)
library(ggpmisc)
library(tibble)
library(fitdistrplus)
library(data.table)
# SET THE WORKING DIRECTORY
rm(list=ls())
set.seed(3)
setwd('/Users/arifinabintarti/Documents/BioRxiv_Seed_Microbiome_2020/16S/')
wd <- print(getwd())
otu.rare.pat <- read.table('single_rare_filt.txt', sep='\t', header=T, row.names = 1)
colnames(otu.rare.pat)
taxonomy.rare.pat <- otu.rare.pat[,'taxonomy']
str(taxonomy.rare.pat)
#write.csv(taxonomy.rare.pat, file = "taxonomy.rare.pat.csv")
dim(otu.rare.pat)
otu.rare.pat <- otu.rare.pat[,-25]
dim(otu.rare.pat)
plant.data = read.csv("planthealthpat.csv", header=T)
map.pat <- plant.data
#checking the colsum and rowsum and produce rarefaction curve
sort(colSums(otu.rare.pat, na.rm = FALSE, dims = 1), decreasing = TRUE)
head(sort(rowSums(otu.rare.pat, na.rm = FALSE, dims = 1), decreasing = FALSE))
rarecurve(t(otu.rare.pat), step = 20, col = "blue", cex = 0.6) #produce the rarefaction curve
################################################################################################################
#calculate alpha diversity
otu.rare.pat <- as.data.frame(otu.rare.pat)
s <- specnumber(otu.rare.pat, MARGIN = 2) # richness
rich <- as.data.frame(s)
h <- diversity(t(otu.rare.pat), index = 'shannon') # Shannon index
shannon <- as.data.frame(h)
j <- h/log(s) # Pielou's evenness
pie <- as.data.frame(j)
map.pat <- plant.data
map.pat$Richness <- s
map.pat$Shannon <- h
map.pat$Pielou <- j
map.pat
#1. Compare bacterial and archaeal richness among different treatments
rich.pat <- aov(map.pat$Richness ~ Treatment, data = map.pat)
summary(rich.pat) #F=2.32, p-val=0.123
# testing assumptions
# Generate residual and predicted values
rich.pat.resids <- residuals(rich.pat)
rich.pat.preds <- predict(rich.pat)
# Perform a Shapiro-Wilk test for normality of residuals
shapiro.test(rich.pat.resids) # p-value = 0.047, data errors are not normally distributed
# Perform Levene's Test for homogenity of variances
leveneTest(Richness ~ Treatment, data=map.pat, na.action=na.exclude) # p-val=0.0055 variances among group are not homogenous
### RESULT: The data does not meet the normality assumption, thus I use Kruskal-Wallis test instead.
kruskal.test(Richness ~ Treatment, data=map.pat) # no signif differences
#2. Compare bacterial and archaeal shannon among different treatments
sha.pat <- aov(map.pat$Shannon ~ Treatment, data = map.pat)
summary(sha.pat) #F=6.009, p-val=0.0086
# testing assumptions
# Generate residual and predicted values
sha.pat.resids <- residuals(sha.pat)
sha.pat.preds <- predict(sha.pat)
# Perform a Shapiro-Wilk test for normality of residuals
shapiro.test(sha.pat.resids) # p-value = 0.02, data errors are not normally distributed
# Perform Levene's Test for homogenity of variances
leveneTest(Shannon ~ Treatment, data=map.pat, na.action=na.exclude) # p-val=0.043 variances among group are not homogenous
### RESULT: The data does not meet the normality assumption, thus I use Kruskal-Wallis test instead.
kruskal.test(Shannon ~ Treatment, data=map.pat) # Kruskal-Wallis chi-squared = 10.64, df = 2, p-value = 0.004893
# there are signif differences
# Do Post Hoc Dunn's Test
sha.dt <- dunnTest(Shannon~Treatment, map.pat, method = "bh", kw=TRUE)
print(sha.dt,dunn.test.results=TRUE)
sha.dt$res
sha.dt.df <- as.data.frame(sha.dt$res)
sha.dt_letter = cldList(P.adj ~ Comparison,
data = sha.dt$res,
threshold = 0.05)
colnames(sha.dt_letter)[colnames(sha.dt_letter)=="Group"] <- "Treatment"
sha_plant.summarized <- map.pat %>% group_by(Treatment) %>% summarize(max.sha=max(Shannon))
sha_plant.summ=left_join(sha.dt_letter,sha_plant.summarized, by='Treatment')
sha_plant.summ
# create new label
label <- c("Control", "Water\nwithholding", "Nutrient\naddition")
# plot
sha<-ggplot(map.pat, aes(x=Treatment, y=Shannon, fill=Treatment)) +
geom_boxplot()+
geom_jitter(height = 0, width = 0.1, alpha = 0.5)+
theme_bw()+
expand_limits(x = 0, y = 0)+
geom_text(data=sha_plant.summ ,aes(x=Treatment,y=0.1+max.sha,label=sha_plant.summ$Letter),vjust=0)+
#geom_errorbar(aes(ymin = mean.podnum - sd.podnum, ymax = mean.podnum + sd.podnum), width=0.2)+
#labs(title = "D. Pod Number", y="Pod count")+
scale_x_discrete(labels= label)+
theme(legend.position="none",
plot.background = element_blank(),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
plot.title = element_text(size = 15, face="bold"),
axis.text=element_text(size=14),
axis.title.x = element_blank(),
axis.title=element_text(size=14,face="bold"),
legend.text=element_text(size=14),
legend.title = element_text(size = 15),
legend.spacing.x = unit(0.05, 'cm'))
sha
sha_plant.summarized <- map.pat %>% group_by(Treatment) %>% summarize(max.sha=max(Shannon))
sha_plant.summ=left_join(sha.dt_letter,sha_plant.summarized, by='Treatment')
sha_plant.summ
# there are signif differences
# Do Post Hoc Dunn's Test
sha.dt <- dunnTest(Shannon~Treatment, map.pat, method = "bh", kw=TRUE)
print(sha.dt,dunn.test.results=TRUE)
sha.dt$res
sha.dt.df <- as.data.frame(sha.dt$res)
sha.dt_letter = cldList(P.adj ~ Comparison,
data = sha.dt$res,
threshold = 0.05)
sha.dt_letter
colnames(sha.dt_letter)[colnames(sha.dt_letter)=="Group"] <- "Treatment"
View(map.pat)
sha_plant.summarized <- map.pat %>%
group_by(Treatment) %>%
summarize(max.sha=max(Shannon))
sha_plant.summarized
sha.dt_letter
sha.dt
sha.dt$res
sha.dt.df <- as.data.frame(sha.dt$res)
sha.dt.df
sha.dt_letter = cldList(P.adj ~ Comparison,
data = sha.dt$res,
threshold = 0.05)
sha.dt_letter
