flips <- c(5, 10, 50, 100)
num_permutations
flips
# setting the alpha
alpha <- 0.05
biases <- seq(0, 1, 0.01)
samplesize_effectsize_estimatedpower <- {}
for(num_flips in flips) {
cat(num_flips, "flips\n")
)
}
# creating a tibble of sample size and fair number of heads
samplesize_fairnumheads <- {}
for(num_flips in flips) {
fair_num_heads <- {}
for(x in 1:num_permutations) {
num_heads <- 0
for(i in 1:num_flips) {
if(runif(1) <= 0.5) {
num_heads <- num_heads + 1
}
}
fair_num_heads <- c(fair_num_heads,
num_heads)
}
samplesize_fairnumheads <- bind_rows(samplesize_fairnumheads,
tibble("samplesize" = rep(sprintf(fmt = "%03d", num_flips), num_permutations),
"fairnumheads" = fair_num_heads))
}
# Plotting null distributions for each sample size
samplesize_fairnumheads %>%
ggplot(aes(x = fairnumheads, fill = samplesize)) +
geom_histogram() +
scale_fill_brewer(palette = "Dark2") +
facet_wrap(~samplesize, nrow = 1, scales = "free") +
theme_bw() +
theme(legend.position = "none")
# setting the alpha
alpha <- 0.05
biases <- seq(0, 1, 0.01)
samplesize_effectsize_estimatedpower <- {}
# adding label of flips
for(num_flips in flips) {
cat(num_flips, "flips\n")
fair_num_heads <- samplesize_fairnumheads %>%
filter(samplesize == rep(sprintf(fmt = "%03d", num_flips))) %>%
pull(fairnumheads)
for(coin_bias in biases) {
num_null_rejects <- 0
for(num_experiments in 1:1000) {
num_heads <- 0
for(i in 1:num_flips) {
if(runif(1) <= coin_bias) {
num_heads <- num_heads + 1 } }
p_value <- sum(abs((num_flips/2) - fair_num_heads) > abs((num_flips/2) - num_heads)) / length(fair_num_heads)
if(p_value < alpha) {
num_null_rejects <- num_null_rejects + 1 } }
estimated_power <- (num_null_rejects / 1000)
samplesize_effectsize_estimatedpower <- rbind(samplesize_effectsize_estimatedpower,
c(num_flips, coin_bias, estimated_power))
}
}
fair_num_heads <- samplesize_fairnumheads %>%
filter(samplesize == rep(sprintf(fmt = "%03d", num_flips))) %>%
pull(fairnumheads)
fair_num_heads
samplesize_fairnumheads
fair_num_heads
fair_num_heads <- samplesize_fairnumheads %>%
filter(samplesize == rep(sprintf(fmt = "%03d", num_flips)))
fair_num_heads
is.data.frame(fair_num_heads)
for(coin_bias in biases) {
num_null_rejects <- 0
for(num_experiments in 1:1000) {
num_heads <- 0
for(i in 1:num_flips) {
if(runif(1) <= coin_bias) {
num_heads <- num_heads + 1 } }
p_value <- sum(abs((num_flips/2) - fair_num_heads) > abs((num_flips/2) - num_heads)) / length(fair_num_heads)
if(p_value < alpha) {
num_null_rejects <- num_null_rejects + 1 } }
estimated_power <- (num_null_rejects / 1000)
samplesize_effectsize_estimatedpower <- rbind(samplesize_effectsize_estimatedpower,
c(num_flips, coin_bias, estimated_power))
}
# make  a data frame of fair number of heads
fair_num_heads <- samplesize_fairnumheads %>%
filter(samplesize == rep(sprintf(fmt = "%03d", num_flips))) %>%
pull(fairnumheads)
for(i in 1:num_flips) {
if(runif(1) <= coin_bias) {
num_heads <- num_heads + 1 } }
num_heads
p_value <- sum(abs((num_flips/2) - fair_num_heads) > abs((num_flips/2) - num_heads)) / length(fair_num_heads)
if(p_value < alpha) {
num_null_rejects <- num_null_rejects + 1 } }
fair_num_heads
samplesize_effectsize_estimatedpower <- tibble("sample_size" = sprintf("%03d", samplesize_effectsize_estimatedpower[,1]),
"effect_size" = samplesize_effectsize_estimatedpower[,2],
"estimated_power" = samplesize_effectsize_estimatedpower[,3])
samplesize_effectsize_estimatedpower
samplesize_effectsize_estimatedpower <- {}
# adding label of flips
for(num_flips in flips) {
cat(num_flips, "flips\n")
# make  a data frame of fair number of heads
fair_num_heads <- samplesize_fairnumheads %>%
filter(samplesize == rep(sprintf(fmt = "%03d", num_flips))) %>%
pull(fairnumheads) #make the vector
for(coin_bias in biases) {
num_null_rejects <- 0
for(num_experiments in 1:1000) {
num_heads <- 0
for(i in 1:num_flips) {
if(runif(1) <= coin_bias) {
num_heads <- num_heads + 1 } }
p_value <- sum(abs((num_flips/2) - fair_num_heads) > abs((num_flips/2) - num_heads)) / length(fair_num_heads)
if(p_value < alpha) {
num_null_rejects <- num_null_rejects + 1 } }
estimated_power <- (num_null_rejects / 1000)
samplesize_effectsize_estimatedpower <- rbind(samplesize_effectsize_estimatedpower,
c(num_flips, coin_bias, estimated_power))
}
}
p_value <- sum(abs((num_flips/2) - fair_num_heads) > abs((num_flips/2) - num_heads)) / length(fair_num_heads)
p_value
# Plotting power curves
samplesize_effectsize_estimatedpower %>%
ggplot(aes(x = effect_size,
y = estimated_power,
color = sample_size,
shape = sample_size)) +
scale_color_brewer(palette = "Dark2") +
geom_point() +
geom_line() +
theme_bw()
#
num_permutations <- 10000
flips <- c(5, 10, 50, 100)
# creating a tibble of sample size and fair number of heads
samplesize_fairnumheads <- {}
for(num_flips in flips) {
fair_num_heads <- {}
for(x in 1:num_permutations) {
num_heads <- 0
for(i in 1:num_flips) {
if(runif(1) <= 0.5) {
num_heads <- num_heads + 1
}
}
fair_num_heads <- c(fair_num_heads,
num_heads)
}
samplesize_fairnumheads <- bind_rows(samplesize_fairnumheads,
tibble("samplesize" = rep(sprintf(fmt = "%03d", num_flips), num_permutations),
"fairnumheads" = fair_num_heads))
}
# Plotting null distributions for each sample size
samplesize_fairnumheads %>%
ggplot(aes(x = fairnumheads, fill = samplesize)) +
geom_histogram() +
scale_fill_brewer(palette = "Dark2") +
facet_wrap(~samplesize, nrow = 1, scales = "free") +
theme_bw() +
theme(legend.position = "none")
# setting the alpha
alpha <- 0.05
# setting the biases
biases <- seq(0, 1, 0.01)
samplesize_effectsize_estimatedpower <- {}
# adding label of flips
for(num_flips in flips) {
cat(num_flips, "flips\n")
# make  a data frame of fair number of heads
fair_num_heads <- samplesize_fairnumheads %>%
filter(samplesize == rep(sprintf(fmt = "%03d", num_flips))) %>%
pull(fairnumheads) #make the vector
for(coin_bias in biases) {
num_null_rejects <- 0
for(num_experiments in 1:1000) {
num_heads <- 0
for(i in 1:num_flips) {
if(runif(1) <= coin_bias) {
num_heads <- num_heads + 1 } }
p_value <- sum(abs((num_flips/2) - fair_num_heads) > abs((num_flips/2) - num_heads)) / length(fair_num_heads)
if(p_value < alpha) {
num_null_rejects <- num_null_rejects + 1 } }
estimated_power <- (num_null_rejects / 1000)
samplesize_effectsize_estimatedpower <- rbind(samplesize_effectsize_estimatedpower,
c(num_flips, coin_bias, estimated_power))
}
}
# estimated the estimated power and effect size
samplesize_effectsize_estimatedpower <- tibble("sample_size" = sprintf("%03d", samplesize_effectsize_estimatedpower[,1]),
"effect_size" = samplesize_effectsize_estimatedpower[,2],
"estimated_power" = samplesize_effectsize_estimatedpower[,3])
# Plotting power curves
samplesize_effectsize_estimatedpower %>%
ggplot(aes(x = effect_size,
y = estimated_power,
color = sample_size,
shape = sample_size)) +
scale_color_brewer(palette = "Dark2") +
geom_point() +
geom_line() +
theme_bw()
fair_num_heads
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
bo <- 12 #the value of y that you get when x =0
sd <- 10
effec.size <- -1.3
# effec.size=mean.diff/sd
mean.diff <- effec.size * sd
mean.diff
rnorm(1000)
data=rnorm(1000)
data
data=rnorm(1000, mean = -13, sd=10)
data
# You may generate values of the predictor variable however you wish.
# lm(outcome ~ predictor, data)
# effect.size = mean(group1)-mean(group2)/sd
# y=b1x + bo
alpha <- 12 #the value of y that you get when x =0
sd <- 10
beta <- -1.3
# effec.size=mean.diff/sd
mean.diff <- effec.size * sd
sigma <- 10
y <- rnorm(1000, mean = -13, sd=10)
y
x <- rnorm(1000,20, 25)
x
x <- rnorm(1000,0, 25)
x
x <- 1:1000
x <- 1:1000
x
x <- rnorm(1000,100,10)
x
knitr::opts_chunk$set(echo = TRUE)
alpha <- 12
sigma <- 10
beta <- -1.3
# lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -13, sd=10)
x <- rnorm(1000,100,10)
# Estimating the mean of a normal
ln.L <- function(y,x,alpha,beta,sigma){
return(sum(
dnorm(y, mean=alpha + beta * x, sd=sigma, log=TRUE)
))
}
alpha <- 12
sigma <- 10
beta <- -1.3
lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -13, sd=10)
x <- rnorm(1000,100,10)
# Estimating the mean of a normal
ln.L <- function(y,x,alpha,beta,sigma){
return(sum(
dnorm(y, mean=alpha + beta * x, sd=sigma, log=TRUE)
))
}
ln.L(y,x,alpha,beta,sigma)
sum(dnorm(y, mean=alpha + beta * x, sd=sigma, log=TRUE)
)
lm <- lm(y ~ (beta*x + alpha, sigma)
data <- data.frame(x,y)
data
lm <- lm(y ~ (beta*x + alpha, sigma),data)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- rnorm(1000,100,10)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
alpha <- 12
sigma <- 10
beta <- -1.3
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(1000,100,10)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(1000,100,0)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(1000,100,10)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(1000,100,10)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(0,10,length.out=1000)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
# lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(1000, 100)
x
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
# lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- rnorm(1000, 100, 10)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
# lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- rnorm(1000, 10, 100)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
# lm <- lm(outcome ~ (beta*predictor + alpha, sigma)
y <- rnorm(1000, mean = -1.3*x+12, sd=10)
x <- seq(10,100, length.out = 1000)
plot(x,y,xlab="predictor", ylab="response")
abline(a=12,b=-1.3,col=2,lwd=2)
adonis(otu_dist~map$pod)
n1 <- 60  				# Number of females
n2 <- 40					# Number of males
mu1 <- 105					# Population mean of females
mu2 <- 77.5					# Population mean of males
sigma1 <- 3				# SD of females
sigma2 <- 2.5  # S
n <- n1+n2					# Total sample size
y1 <- rnorm(n1, mu1, sigma1)		# Data for females separately
y2 <- rnorm(n2, mu2, sigma2)		# Data for males separately
n <- n1+n2					# Total sample size
y1 <- rnorm(n1, mu1, sigma1)		# Data for females separately
y2 <- rnorm(n2, mu2, sigma2)		# Data for males separately
n
y1
y2
data2 <- data.frame(y=c(y1, y2), sex=c(rep("f",n1),rep("m",n2)))			# Aggregate both data sets
data2
boxplot(data2$y ~ data2$sex, col = "grey", xlab = "Sex", ylab = "Wingspan (cm)", las = 1)
#Simulate the data
n1 <- 60  				# Number of females
n2 <- 40					# Number of males
mu1 <- 105					# Population mean of females
mu2 <- 77.5					# Population mean of males
sigma <- 2.75				# Average population SD of both
n <- n1+n2					# Total sample size
y1 <- rnorm(n1, mu1, sigma)		# Data for females separately
y2 <- rnorm(n2, mu2, sigma)		# Data for males separately
data1 <- data.frame(y=c(y1, y2), sex=c(rep("f",n1),rep("m",n2)))			# Aggregate both data sets
boxplot(data1$y ~ data1$sex, col = "grey", xlab = "Sex", ylab = "Wingspan (cm)", las = 1)
n <- n1+n2  				# Total sample size
alpha <- mu1				# Mean for females serves as the intercept
beta <- mu2-mu1				# Beta is the difference male-female
E.y <- alpha + beta*x			# expectation
y.obs <- rnorm(n = n, mean = E.y, sd = sigma)	# Add random variation
x <- rep(c(0,1), c(n1, n2))		# Indicator for male
boxplot(y.obs ~ x, col = "grey", xlab = "Male", ylab = "Wingspan (cm)", las = 1)
fit1 <- lm(data1$y ~ data1$sex)  		# Analyze the data with an effects parameterization
fit2 <- lm(data1$y ~ data1$sex-1) 		# Analyze the data with a means parameterization
summary(fit1)
summary(fit2)
#Take a look at the design matrices for the two models (are they the same?):
model.matrix(fit1)
model.matrix(fit2)
#What is the interpretation of the coefficients?
fit1$coefficients
fit2$coefficients
#Is there a difference in wingspan between males and females?
#It's easiest to figure this out using fit1.  Why?
confint(fit1)
#But we can also tell with the means parameterization
confint(fit2)
#Pull out the residuals
residual = fit1$residuals
predicted= fit1$fitted.values
#Is there a pattern in the residuals?
plot(predicted, residual, main = "Residuals vs. predicted values",
las = 1, xlab = "Predicted values", ylab = "Residuals")
abline(h = 0)
#Another way to do this analysis is with the function t.test
t.test(data1$y ~ data1$sex, var.equal=TRUE)
#Simulate the data
n1 <- 60  				# Number of females
n2 <- 40					# Number of males
mu1 <- 105					# Population mean of females
mu2 <- 77.5					# Population mean of males
sigma1 <- 3				# SD of females
sigma2 <- 2.5  # SD of males
n <- n1+n2					# Total sample size
y1 <- rnorm(n1, mu1, sigma1)		# Data for females separately
y2 <- rnorm(n2, mu2, sigma2)		# Data for males separately
data2 <- data.frame(y=c(y1, y2), sex=c(rep("f",n1),rep("m",n2)))			# Aggregate both data sets
boxplot(data2$y ~ data2$sex, col = "grey", xlab = "Sex", ylab = "Wingspan (cm)", las = 1)
t.test(data2$y ~ data2$sex, var.equal=FALSE)
R. version
version
version
library(BiocManager)
library(vegan)
library(plyr)
library(dplyr)
library(tidyverse)
library(tidyr)
library(cowplot)
library(ggplot2)
library(reshape)
library(ggpubr)
library(car)
library(agricolae)
library(multcompView)
library(grid)
library(gridExtra)
library(sjmisc)
library(sjPlot)
library(MASS)
library(FSA)
library(rcompanion)
library(onewaytests)
library(ggsignif)
library(PerformanceAnalytics)
library(gvlma)
library(userfriendlyscience)
library(ggpmisc)
library(tibble)
library(fitdistrplus)
library(data.table)
rm(list=ls())
set.seed(3)
setwd('/Users/arifinabintarti/Documents/BioRxiv_Seed_Microbiome_2020/16S/')
wd <- print(getwd())
otu.rare.pat <- read.table('single_rare.txt', sep='\t', header=T, row.names = 1)
colnames(otu.rare.pat)
taxonomy.rare.pat <- otu.rare.pat[,'taxonomy']
str(taxonomy.rare.pat)
dim(otu.rare.pat)
otu.rare.pat <- otu.rare.pat[,-25]
dim(otu.rare.pat)
plant.data = read.csv("planthealthpat.csv", header=T)
map.pat <- plant.data
sort(colSums(otu.rare.pat, na.rm = FALSE, dims = 1), decreasing = TRUE)
head(sort(rowSums(otu.rare.pat, na.rm = FALSE, dims = 1), decreasing = FALSE))
rarecurve(t(otu.rare.pat), step = 20, col = "blue", cex = 0.6)
otu.rare.pat <- as.data.frame(otu.rare.pat)
s <- specnumber(otu.rare.pat, MARGIN = 2) # richness
rich <- as.data.frame(s)
h <- diversity(t(otu.rare.pat), index = 'shannon') # Shannon index
shannon <- as.data.frame(h)
j <- h/log(s) # Pielou's evenness
pie <- as.data.frame(j)
map.pat <- plant.data
map.pat$Richness <- s
map.pat$Shannon <- h
map.pat$Pielou <- j
map.pat
#add Faith's PD index
pd.index <- read.table('PD_whole_tree.txt', sep='\t', header=T, row.names = 1)
pd.index <- rownames_to_column(pd.index, "Plant.Name")
#join aith's PD index to the map
map.pat <- merge(map.pat, pd.index, by="Plant.Name", all = T)
